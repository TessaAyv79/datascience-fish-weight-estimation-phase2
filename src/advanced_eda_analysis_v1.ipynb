{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-depth Exploratory Data Analysis (EDA) and Model Explainability for Fish Species Classification\n",
    "\n",
    "This Jupyter notebook demonstrates an in-depth exploratory data analysis (EDA) pipeline and model explainability using `SHAP` for an image classification task. The primary objective of this project is to classify fish species and potentially estimate their weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation and Import of Essential Libraries\n",
    "\n",
    "This section ensures that all necessary Python libraries for the analysis are installed and imported. Libraries like `missingno` are used for visualizing missing values, `seaborn` and `matplotlib` for general visualizations, and `tensorflow` and `keras` for model building. `shap` is the core library for model explainability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: missingno in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (0.5.2)\n",
      "Requirement already satisfied: shap in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (0.48.0)\n",
      "Requirement already satisfied: scipy in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from missingno) (1.15.3)\n",
      "Requirement already satisfied: matplotlib in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from missingno) (3.10.0)\n",
      "Requirement already satisfied: seaborn in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from missingno) (0.13.2)\n",
      "Requirement already satisfied: numpy in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from missingno) (1.24.4)\n",
      "Requirement already satisfied: packaging>20.9 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from shap) (25.0)\n",
      "Requirement already satisfied: cloudpickle in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from shap) (3.1.1)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from shap) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from shap) (1.2.2)\n",
      "Requirement already satisfied: numba>=0.54 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from shap) (0.61.0)\n",
      "Requirement already satisfied: slicer==0.0.8 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: pandas in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from shap) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from shap) (4.14.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from numba>=0.54->shap) (0.44.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from matplotlib->missingno) (3.2.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from matplotlib->missingno) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from matplotlib->missingno) (11.2.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from matplotlib->missingno) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from matplotlib->missingno) (4.58.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from matplotlib->missingno) (2.9.0.post0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from matplotlib->missingno) (0.12.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from pandas->shap) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from pandas->shap) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from scikit-learn->shap) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from scikit-learn->shap) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->missingno) (1.17.0)\n",
      "Requirement already satisfied: tensorflow in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (2.19.0)\n",
      "Requirement already satisfied: keras in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (3.10.0)\n",
      "Requirement already satisfied: matplotlib in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (3.10.0)\n",
      "Requirement already satisfied: numpy in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (1.24.4)\n",
      "Requirement already satisfied: seaborn in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from tensorflow) (1.73.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from tensorflow) (4.14.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: packaging in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from tensorflow) (25.2.10)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: setuptools in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: namex in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from keras) (0.1.0)\n",
      "Requirement already satisfied: rich in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from keras) (14.0.0)\n",
      "Requirement already satisfied: optree in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from keras) (0.16.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: pillow>=8 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from seaborn) (2.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (3.8.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from rich->keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/tessaayv/datascience-weight-estimation/venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n",
      "Successfully installed numpy-2.1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-19 21:01:46.662940: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750366906.691250 1772618 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750366906.699130 1772618 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750366906.721640 1772618 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750366906.721671 1772618 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750366906.721674 1772618 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750366906.721676 1772618 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-19 21:01:46.728729: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Image processing and modeling libraries\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential, load_model, Model\n",
      "File \u001b[0;32m~/datascience-weight-estimation/venv/lib/python3.10/site-packages/tensorflow/__init__.py:468\u001b[0m\n\u001b[1;32m    466\u001b[0m     importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_keras.src.optimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    467\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 468\u001b[0m     \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeras.src.optimizers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[1;32m    470\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/datascience-weight-estimation/venv/lib/python3.10/site-packages/keras/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _tf_keras \u001b[38;5;28;01mas\u001b[39;00m _tf_keras\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m activations \u001b[38;5;28;01mas\u001b[39;00m activations\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m applications \u001b[38;5;28;01mas\u001b[39;00m applications\n",
      "File \u001b[0;32m~/datascience-weight-estimation/venv/lib/python3.10/site-packages/keras/_tf_keras/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tf_keras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "File \u001b[0;32m~/datascience-weight-estimation/venv/lib/python3.10/site-packages/keras/_tf_keras/keras/__init__.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils \u001b[38;5;28;01mas\u001b[39;00m utils\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m visualization \u001b[38;5;28;01mas\u001b[39;00m visualization\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m wrappers \u001b[38;5;28;01mas\u001b[39;00m wrappers\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend \u001b[38;5;28;01mas\u001b[39;00m backend\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers \u001b[38;5;28;01mas\u001b[39;00m layers\n",
      "File \u001b[0;32m~/datascience-weight-estimation/venv/lib/python3.10/site-packages/keras/wrappers/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msklearn_wrapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     SKLearnClassifier \u001b[38;5;28;01mas\u001b[39;00m SKLearnClassifier,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msklearn_wrapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     SKLearnRegressor \u001b[38;5;28;01mas\u001b[39;00m SKLearnRegressor,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msklearn_wrapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     14\u001b[0m     SKLearnTransformer \u001b[38;5;28;01mas\u001b[39;00m SKLearnTransformer,\n\u001b[1;32m     15\u001b[0m )\n",
      "File \u001b[0;32m~/datascience-weight-estimation/venv/lib/python3.10/site-packages/keras/src/wrappers/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msklearn_wrapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SKLearnClassifier\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msklearn_wrapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SKLearnRegressor\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msklearn_wrapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SKLearnTransformer\n",
      "File \u001b[0;32m~/datascience-weight-estimation/venv/lib/python3.10/site-packages/keras/src/wrappers/sklearn_wrapper.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloning\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone_model\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _routing_enabled\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _validate_data\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m type_of_target\n",
      "File \u001b[0;32m~/datascience-weight-estimation/venv/lib/python3.10/site-packages/keras/src/wrappers/fixes.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m      4\u001b[0m     sklearn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/datascience-weight-estimation/venv/lib/python3.10/site-packages/sklearn/__init__.py:82\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _distributor_init  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __check_build  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[1;32m     85\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    129\u001b[0m ]\n",
      "File \u001b[0;32m~/datascience-weight-estimation/venv/lib/python3.10/site-packages/sklearn/base.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_set_output\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _SetOutputMixin\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tags\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m     _DEFAULT_TAGS,\n\u001b[1;32m     21\u001b[0m )\n",
      "File \u001b[0;32m~/datascience-weight-estimation/venv/lib/python3.10/site-packages/sklearn/utils/__init__.py:19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmurmurhash\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m murmurhash3_32\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclass_weight\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute_class_weight, compute_sample_weight\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _joblib\n",
      "File \u001b[0;32msklearn/utils/murmurhash.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.utils.murmurhash\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "# Check and install libraries\n",
    "!pip install missingno shap\n",
    "!pip install tensorflow keras matplotlib numpy seaborn scikit-learn\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "from collections import Counter\n",
    "\n",
    "# Image processing and modeling libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import ResNet50, InceptionV3, MobileNetV2\n",
    "\n",
    "# SHAP for model explainability\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Interpretation:**\n",
    "This cell primarily shows the output of `pip install` commands, indicating whether the required packages are already satisfied or are being installed. This ensures all dependencies are met before proceeding with the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Organization and Preparation\n",
    "\n",
    "This section covers the examination of the dataset's folder structure and the application of data augmentation and preprocessing steps using `ImageDataGenerator` for the training, validation, and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Creating Dataset Folder Structure and Distributing Images\n",
    "\n",
    "Model training to start, it is crucial to divide the dataset into training, validation, and test sets and place them into an appropriate folder structure. This section outlines the process of taking all fish images from an `all_images` folder and copying them into respective subfolders (e.g., 70% for training, 15% for validation, 15% for testing). This ensures a balanced distribution of images across each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to organize the dataset\n",
    "def create_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        print(f\"Created: {path}\")\n",
    "    else:\n",
    "        print(f\"Already exists: {path}\")\n",
    "\n",
    "def distribute_images(src_dir, train_dir, val_dir, test_dir, train_split=0.7, val_split=0.15):\n",
    "    class_names = [d for d in os.listdir(src_dir) if os.path.isdir(os.path.join(src_dir, d))]\n",
    "    \n",
    "    for class_name in class_names:\n",
    "        class_src_path = os.path.join(src_dir, class_name)\n",
    "        \n",
    "        # Create class directories for each subset\n",
    "        create_directory(os.path.join(train_dir, class_name))\n",
    "        create_directory(os.path.join(val_dir, class_name))\n",
    "        create_directory(os.path.join(test_dir, class_name))\n",
    "        \n",
    "        images = [f for f in os.listdir(class_src_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        random.shuffle(images) # Shuffle images\n",
    "        \n",
    "        # Calculate split counts\n",
    "        train_count = int(len(images) * train_split)\n",
    "        val_count = int(len(images) * val_split)\n",
    "        \n",
    "        train_images = images[:train_count]\n",
    "        val_images = images[train_count:train_count + val_count]\n",
    "        test_images = images[train_count + val_count:] # Remaining images for test set\n",
    "\n",
    "        print(f\"\\nClass: {class_name}\")\n",
    "        print(f\"  Training: {len(train_images)} images\")\n",
    "        print(f\"  Validation: {len(val_images)} images\")\n",
    "        print(f\"  Test: {len(test_images)} images\")\n",
    "\n",
    "        # Copy images\n",
    "        for img in train_images:\n",
    "            shutil.copy(os.path.join(class_src_path, img), os.path.join(train_dir, class_name, img))\n",
    "        for img in val_images:\n",
    "            shutil.copy(os.path.join(class_src_path, img), os.path.join(val_dir, class_name, img))\n",
    "        for img in test_images:\n",
    "            shutil.copy(os.path.join(class_src_path, img), os.path.join(test_dir, class_name, img))\n",
    "\n",
    "# Define the base dataset path\n",
    "base_dir = '/home/tessaayv/datascience-weight-estimation/TheFishProject4_v1/datasets/'\n",
    "all_images_dir = os.path.join(base_dir, 'all_images') # Main folder containing all images\n",
    "\n",
    "# Define the new folder structure for species classification\n",
    "train_species_dir = os.path.join(base_dir, 'species/train')\n",
    "val_species_dir = os.path.join(base_dir, 'species/val')\n",
    "test_species_dir = os.path.join(base_dir, 'species/test')\n",
    "\n",
    "# Create main directories\n",
    "create_directory(train_species_dir)\n",
    "create_directory(val_species_dir)\n",
    "create_directory(test_species_dir)\n",
    "\n",
    "# Distribute images (run only on first execution or if redistribution is needed)\n",
    "# If you have already manually organized your dataset or it's already structured, do not run this.\n",
    "# distribute_images(all_images_dir, train_species_dir, val_species_dir, test_species_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Screenshots (Folder Creation Output):**\n",
    "These outputs confirm that the necessary directories for the training, validation, and test sets were successfully created. If the directories already exist, they will show \"Already exists\".\n",
    "\n",
    "![Folder Creation 1](Screenshot%202025-06-19%20155603.png)\n",
    "![Folder Creation 2](Screenshot%202025-06-19%20155617.png)\n",
    "![Folder Creation 3](Screenshot%202025-06-19%20155659.png)\n",
    "![Folder Creation 4](Screenshot%202025-06-19%20155713.png)\n",
    "![Folder Creation 5](Screenshot%202025-06-19%20155727.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Interpretation:**\n",
    "The series of screenshots `Screenshot 2025-06-19 155603.png` to `Screenshot 2025-06-19 155727.png` illustrate the execution of the `create_directory` function. For each path (`/home/tessaayv/datascience-weight-estimation/TheFishProject4_v1/datasets/species/train`, `/home/tessaayv/datascience-weight-estimation/TheFishProject4_v1/datasets/species/val`, `/home/tessaayv/datascience-weight-estimation/TheFishProject4_v1/datasets/species/test`), the script checks if the directory exists and either creates it or confirms its existence. This is a crucial initial step to ensure the data is organized correctly for the `ImageDataGenerator`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Folder Structure and File Count Verification\n",
    "\n",
    "The base directory of the dataset is defined, and the number of files within each subfolder is verified. This step is essential to ensure that the dataset has been loaded and distributed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base dataset path (can be adjusted if the distribution step above was not run or if coming from a different source)\n",
    "base_dir = '/home/tessaayv/datascience-weight-estimation/TheFishProject4_v1/datasets/' # Use the correct path for your current setup\n",
    "\n",
    "# Check if directories exist\n",
    "train_dir = os.path.join(base_dir, 'species/train')\n",
    "val_dir = os.path.join(base_dir, 'species/val')\n",
    "test_dir = os.path.join(base_dir, 'species/test')\n",
    "\n",
    "print(f\"Train directory exists: {os.path.exists(train_dir)}\")\n",
    "print(f\"Val directory exists: {os.path.exists(val_dir)}\")\n",
    "print(f\"Test directory exists: {os.path.exists(test_dir)}\")\n",
    "\n",
    "# Function to count images in a directory\n",
    "def count_images_in_directory(directory):\n",
    "    counts = {}\n",
    "    if os.path.exists(directory):\n",
    "        for class_name in os.listdir(directory):\n",
    "            class_path = os.path.join(directory, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                counts[class_name] = len([f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    return counts\n",
    "\n",
    "train_counts = count_images_in_directory(train_dir)\n",
    "val_counts = count_images_in_directory(val_dir)\n",
    "test_counts = count_images_in_directory(test_dir)\n",
    "\n",
    "print(\"\\nTraining Set Class Distribution:\")\n",
    "for cls, count in train_counts.items():\n",
    "    print(f\"  {cls}: {count} images\")\n",
    "\n",
    "print(\"\\nValidation Set Class Distribution:\")\n",
    "for cls, count in val_counts.items():\n",
    "    print(f\"  {cls}: {count} images\")\n",
    "\n",
    "print(\"\\nTest Set Class Distribution:\")\n",
    "for cls, count in test_counts.items():\n",
    "    print(f\"  {cls}: {count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Screenshot (Class and Sample Counts - Summary):**\n",
    "This output shows the number of images for each fish species (class) in the training, validation, and test sets. This is important for understanding the balance of the dataset and identifying potential class imbalances.\n",
    "\n",
    "![Class and Sample Counts Summary](Screenshot%202025-06-19%20155750.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Screenshots (Class and Sample Counts - Detailed):**\n",
    "These screenshots demonstrate the detailed listing of image counts per class within each subset by the `count_images_in_directory` function. This is particularly useful for verifying that the dataset has been correctly split.\n",
    "\n",
    "![Class Count Detail 1](Screenshot%202025-06-19%20155956.png)\n",
    "![Class Count Detail 2](Screenshot%202025-06-19%20160016.png)\n",
    "![Class Count Detail 3](Screenshot%202025-06-19%20160030.png)\n",
    "![Class Count Detail 4](Screenshot%202025-06-19%20160041.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Interpretation:**\n",
    "The outputs from `Screenshot 2025-06-19 155750.png` to `Screenshot 2025-06-19 160041.png` provide a comprehensive overview of the class distribution across the training, validation, and test sets. For example, `Screenshot 2025-06-19 155750.png` shows the top-level counts like \"Training Set Class Distribution: Red_Sea_Bream: 151 images\". The subsequent detailed screenshots (`155956.png` to `160041.png`) then show the specific counts for each class within each of the `train_counts`, `val_counts`, and `test_counts` dictionaries. This detailed breakdown confirms the successful and potentially balanced distribution of images across the different classes and subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Data Augmentation and Preprocessing with ImageDataGenerator\n",
    "\n",
    "`ImageDataGenerator` is used to prepare image data for the model. This not only applies data augmentation (e.g., rotation, shifting, zooming) to improve the model's generalization capability but also rescales pixels (to the 0-1 range), allowing the model to learn more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dimensions and batch size\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# ImageDataGenerator definitions for data augmentation and preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create data flows (data generators)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False # Set shuffle to False for test set to maintain order for evaluation\n",
    ")\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "print(f\"Total number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Screenshot (ImageDataGenerator Output):**\n",
    "This output shows how many images `ImageDataGenerator` found from the training, validation, and test sets and how many classes it identified.\n",
    "\n",
    "![ImageDataGenerator Output](Screenshot%202025-06-19%20155812.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Interpretation:**\n",
    "The output from `Screenshot 2025-06-19 155812.png` confirms that the `ImageDataGenerator` successfully identified and loaded images from the specified directories. It indicates:\n",
    "* **Training Generator:** \"Found 1464 images belonging to 5 classes.\" This means the training set has 1464 images distributed among 5 distinct fish species.\n",
    "* **Validation Generator:** \"Found 312 images belonging to 5 classes.\" Similarly, the validation set contains 312 images across the same 5 classes.\n",
    "* **Test Generator:** \"Found 318 images belonging to 5 classes.\" The test set comprises 318 images for the 5 classes.\n",
    "This output verifies that the data loading pipeline is correctly set up, and the number of classes aligns with the problem definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visual Exploratory Data Analysis (EDA)\n",
    "\n",
    "This section involves the visual inspection of images within the dataset and the graphical representation of class distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Displaying Sample Images\n",
    "\n",
    "Displaying a few randomly selected images from the training set provides a quick insight into the content and quality of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "def plot_sample_images(generator, num_images=5):\n",
    "    images, labels = next(generator) # Get a batch\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        class_name = list(generator.class_indices.keys())[np.argmax(labels[i])]\n",
    "        plt.title(f\"Class: {class_name}\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nSample images from the training set:\")\n",
    "plot_sample_images(train_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Screenshot (Sample Images):**\n",
    "This visualization presents sample augmented training images with their corresponding labels.\n",
    "\n",
    "![Sample Images](Screenshot%202025-06-19%20160645.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Interpretation:**\n",
    "The image `Screenshot 2025-06-19 160645.png` displays 5 sample images from the training set, each labeled with its corresponding fish species (e.g., \"Class: Red_Sea_Bream\", \"Class: Striped_Red_Mullet\"). This visualization helps to visually inspect the data quality, diversity, and the effects of data augmentation (e.g., variations in orientation, size, and position of the fish). It confirms that the images are correctly loaded and associated with their respective classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Visualizing Class Distributions\n",
    "\n",
    "Visualizing class distributions in the training, validation, and test sets with bar plots helps identify potential imbalances in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize class distributions\n",
    "def plot_class_distribution(directory, title):\n",
    "    counts = count_images_in_directory(directory)\n",
    "    if not counts:\n",
    "        print(f\"Warning: No images found in {directory}.\")\n",
    "        return\n",
    "\n",
    "    classes = list(counts.keys())\n",
    "    values = list(counts.values())\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=classes, y=values, palette='viridis')\n",
    "    plt.title(f'{title} Class Distribution')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClass Distributions:\")\n",
    "plot_class_distribution(train_dir, 'Training Set')\n",
    "plot_class_distribution(val_dir, 'Validation Set')\n",
    "plot_class_distribution(test_dir, 'Test Set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Screenshot (Class Distributions - Training Set):**\n",
    "This graph shows how many images each fish species (class) has in the training set.\n",
    "\n",
    "![Training Set Class Distribution](Screenshot%202025-06-19%20160758.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Screenshot (Class Distributions - Validation Set):**\n",
    "This graph shows how many images each fish species (class) has in the validation set.\n",
    "\n",
    "![Validation Set Class Distribution](Screenshot%202025-06-19%20160811.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Screenshot (Class Distributions - Test Set):**\n",
    "This graph shows how many images each fish species (class) has in the test set.\n",
    "\n",
    "![Test Set Class Distribution](Screenshot%202025-06-19%20160824.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Interpretation:**\n",
    "The series of bar plots (from `Screenshot 2025-06-19 160758.png` to `Screenshot 2025-06-19 160824.png`) visually represent the distribution of images across different fish species in the training, validation, and test sets.\n",
    "* **Training Set (160758.png):** Shows the image counts for each species in the training data (e.g., Red Sea Bream, Striped Red Mullet, Horse Mackerel). This helps identify if any class is significantly over- or under-represented.\n",
    "* **Validation Set (160811.png):** Presents the same distribution for the validation set, which is crucial for monitoring model performance during training without directly influencing it.\n",
    "* **Test Set (160824.png):** Displays the distribution for the test set, ensuring that the final evaluation is performed on a representative sample of unseen data.\n",
    "Overall, these graphs help in understanding data balance, which is important for preventing bias in model training and ensuring robust evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building and Training the Model with Transfer Learning\n",
    "\n",
    "In this section, an image classification model is built and trained using transfer learning with a pre-trained neural network (ResNet50)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Loading and Configuring the ResNet50 Model\n",
    "\n",
    "The top layers of the ResNet50 model are removed, and new classification layers are added. This allows for the creation of a specialized model for the fish species classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model for transfer learning (ResNet50)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "# Freeze the base model (to prevent its weights from changing)\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add new classification layers\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Screenshot (Model Summary):**\n",
    "This output displays the layers, output shapes, and parameter counts of the constructed neural network model.\n",
    "\n",
    "![Model Summary](Screenshot%202025-06-19%20160833.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Interpretation:**\n",
    "The screenshot `Screenshot 2025-06-19 160833.png` shows the `model.summary()` output. This provides a detailed breakdown of the model architecture, including:\n",
    "* **Layer (type) and Output Shape:** Each layer in the `Sequential` model is listed, along with its type (e.g., `ResNet50`, `GlobalAveragePooling2D`, `Dense`, `Dropout`) and the shape of its output tensor. This helps in understanding the flow of data through the network.\n",
    "* **Param #:** The number of trainable parameters in each layer. Crucially, the `resnet50` layer shows `0` trainable parameters, indicating that its weights are frozen (`base_model.trainable = False`), as intended for transfer learning. The majority of trainable parameters are in the newly added `dense` layers, which will learn to classify the fish species.\n",
    "This summary is essential for verifying that the model has been constructed correctly and that transfer learning has been applied as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Model Training\n",
    "\n",
    "The model is trained on the training and validation sets using the defined `ImageDataGenerator`s. Callbacks such as `EarlyStopping`, `ModelCheckpoint`, and `ReduceLROnPlateau` are used to optimize the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_fish_species_model.h5', monitor='val_accuracy', save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    epochs=50,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // BATCH_SIZE,\n",
    "    callbacks=[early_stopping, model_checkpoint, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Interpretation:**\n",
    "The output of the `model.fit()` command is a verbose log of the training process across epochs. It typically shows:\n",
    "* **Epoch number:** The current training epoch.\n",
    "* **Loss and Accuracy for Training Data:** The `loss` (categorical cross-entropy) and `accuracy` on the training set for that epoch.\n",
    "* **Validation Loss and Accuracy:** The `val_loss` and `val_accuracy` on the validation set, which are crucial for monitoring overfitting.\n",
    "* **Time taken per epoch:** How long each epoch took to complete.\n",
    "* **Callbacks in action:** Messages from `EarlyStopping` (e.g., \"Restoring best model weights from the end of the best epoch.\") or `ReduceLROnPlateau` (e.g., \"Epoch X: ReduceLROnPlateau reducing learning rate to...\").\n",
    "This output is vital for understanding the model's learning progress, identifying convergence, and detecting signs of overfitting or underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Performance Evaluation\n",
    "\n",
    "After training, the model's performance is analyzed by plotting training and validation loss/accuracy graphs and evaluating it on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Visualizing Training and Validation Metrics\n",
    "\n",
    "Model's learning curves (loss and accuracy) during the training process helps identify issues like overfitting or underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation results\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Interpretation:**\n",
    "This section would ideally show two plots: one for \"Training and Validation Accuracy\" over epochs and another for \"Training and Validation Loss\" over epochs.\n",
    "* **Accuracy Plot:** We would expect to see both training and validation accuracy increasing over epochs. Ideally, they should converge or stay close to each other. A significant gap where training accuracy is much higher than validation accuracy indicates overfitting.\n",
    "* **Loss Plot:** Similarly, both training and validation loss should decrease over epochs. If validation loss starts increasing while training loss continues to decrease, it's another strong sign of overfitting.\n",
    "These plots are critical for diagnostics during model development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Model Evaluation on the Test Set\n",
    "\n",
    "A final evaluation is performed on the test set to measure the model's generalization capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "best_model = load_model('best_fish_species_model.h5')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_loss, test_accuracy = best_model.evaluate(test_generator)\n",
    "print(f\"\\nTest Set Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Set Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Screenshot (Test Set Evaluation):**\n",
    "This output displays the final accuracy and loss values of the model on the unseen test set.\n",
    "\n",
    "![Test Set Evaluation](Screenshot%202025-06-19%20160844.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Interpretation:**\n",
    "The screenshot `Screenshot 2025-06-19 160844.png` shows the result of the `best_model.evaluate(test_generator)` call.\n",
    "* **`20/20 [==============================] - 5s 237ms/step - loss: 0.2882 - accuracy: 0.9088`**: This line indicates the progress of the evaluation (20 batches processed out of 20) and the final metrics.\n",
    "* **`Test Set Loss: 0.2882`**: This is the final loss value on the test set. A lower loss indicates better model performance.\n",
    "* **`Test Set Accuracy: 0.9088`**: This is the final accuracy on the test set, meaning the model correctly classified approximately 90.88% of the images in the unseen test dataset.\n",
    "This result is a key indicator of the model's real-world performance and its ability to generalize to new, unseen data. An accuracy of ~91% is quite good for a multi-class image classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Explainability (SHAP)\n",
    "\n",
    "Using SHAP (SHapley Additive exPlanations), we visualize which pixels or regions contribute more to an image's classification decision, thereby explaining the model's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Loading Sample Images and Defining SHAP Explainer\n",
    "\n",
    "Sample images to be used in the SHAP analysis are loaded, and a `shap.Explainer` object is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load sample images from a directory\n",
    "def load_images_from_directory(directory_path, target_size=(224, 224), max_images_per_class=1):\n",
    "    images = []\n",
    "    class_names = [d for d in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, d))]\n",
    "    \n",
    "    # Get a specific number of images from each class\n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(directory_path, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            current_images_in_class = []\n",
    "            for fname in os.listdir(class_path):\n",
    "                if fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    current_images_in_class.append(os.path.join(class_path, fname))\n",
    "            \n",
    "            # Randomly select max_images_per_class\n",
    "            random.shuffle(current_images_in_class)\n",
    "            for i, img_path in enumerate(current_images_in_class):\n",
    "                if i >= max_images_per_class:\n",
    "                    break\n",
    "                img = image.load_img(img_path, target_size=target_size)\n",
    "                img_array = image.img_to_array(img) / 255.0  # Normalize\n",
    "                images.append(img_array)\n",
    "    return np.array(images)\n",
    "\n",
    "# Load sample images from the test set for SHAP analysis (e.g., 1 image per class)\n",
    "sample_images = load_images_from_directory(test_dir, max_images_per_class=1, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "\n",
    "# Define masker for SHAP\n",
    "# An inpainting algorithm like \"inpaint_telea\" fills masked regions realistically.\n",
    "masker = shap.maskers.Image(\"inpaint_telea\", sample_images[0].shape)\n",
    "\n",
    "# Create SHAP Explainer\n",
    "# The model's prediction function and the masker are provided to the SHAP Explainer.\n",
    "# PermutationExplainer is general and can work with any model.\n",
    "explainer = shap.Explainer(best_model.predict, masker)\n",
    "\n",
    "# Compute SHAP values\n",
    "# Calculate SHAP values for each image in the sample_images array\n",
    "shap_values = explainer(sample_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Interpretation:**\n",
    "This section primarily runs the SHAP calculation, which doesn't produce direct console output unless there are warnings or errors. The critical part is the creation of `shap_values`, which contain the attribution scores for each pixel in the input images, indicating their contribution to the model's output for each class. The setup of the `load_images_from_directory` function also shows how sample images are chosen for explanation, ensuring diversity across classes if `max_images_per_class` is set appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Visualizing SHAP Values\n",
    "\n",
    "SHAP values are visualized as heatmaps, showing the contribution of each pixel to the model's output. This allows us to understand which visual features the model focuses on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize SHAP values\n",
    "# Uses `sample_images` and `shap_values` for visualization.\n",
    "# Plot SHAP explanation for each sample image\n",
    "for i in range(len(sample_images)):\n",
    "    print(f\"\\n--- SHAP Explanation for Image {i+1} ---\")\n",
    "    # shap_values[i] directly contains SHAP values for all classes for the i-th image.\n",
    "    # shap.image_plot expects this format.\n",
    "    shap.image_plot(shap_values[i].values, sample_images[i:i+1]) # Use slicing for a single image display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Screenshot (SHAP Explanation - Sample 1):**\n",
    "This visualization displays the SHAP values (importance maps) for the first sample image. Red regions indicate pixels that positively contribute to the model's prediction for a specific class, while blue regions indicate negative contributions.\n",
    "\n",
    "![SHAP Explanation - Sample 1](Screenshot%202025-06-19%20160904.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Screenshot (SHAP Explanation - Sample 2):**\n",
    "This visualization displays the SHAP values (importance maps) for the second sample image. Similarly, red and blue regions indicate pixel contributions.\n",
    "\n",
    "![SHAP Explanation - Sample 2](Screenshot%202025-06-19%20160916.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Interpretation:**\n",
    "The screenshots `Screenshot 2025-06-19 160904.png` and `Screenshot 2025-06-19 160916.png` are crucial for model interpretability. They show:\n",
    "* **Original Image:** The initial image that was input to the model.\n",
    "* **Prediction and SHAP Values:** For each image, the model's prediction (e.g., \"Predicted: Red_Sea_Bream\") is shown, along with a heatmap overlay.\n",
    "* **Heatmap (Red/Blue):**\n",
    "    * **Red areas** highlight pixels that have a strong *positive* influence on the model's prediction for the predicted class. These are the features the model found most important for its decision. For example, in a fish image, the outline of the fish, its fins, or specific patterns might be highlighted in red.\n",
    "    * **Blue areas** highlight pixels that have a strong *negative* influence. These pixels, if present or different, would push the model's prediction away from the chosen class.\n",
    "By examining these SHAP plots, one can understand *why* the model made a particular classification. For instance, if the model classified an image as \"Red Sea Bream\" and the SHAP plot highlights the distinct shape of the fish or its scales, it indicates that the model is using relevant visual cues, thus increasing trust in its predictions. This is invaluable for debugging, building confidence, and understanding potential biases in the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
